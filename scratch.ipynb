{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('ogb-lsc-env': conda)",
   "metadata": {
    "interpreter": {
     "hash": "4884a46182a36c52786c58ae747f94ef8bde10a8978cfcd06107010b24cc677d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch \n",
    "from ogb.utils import smiles2graph\n",
    "from ogb.lsc import DglPCQM4MDataset\n",
    "import networkx as nx\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DglPCQM4MDataset(root='/home/ksadowski/datasets', smiles2graph=smiles2graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molecule = dgl.to_homogeneous(dataset[2736][0], ndata=dataset[2736][0].ndata, edata=dataset[2736][0].edata, store_type=False)\n",
    "molecule_lg = dgl.line_graph(molecule, backtracking=False)\n",
    "\n",
    "# molecule = dgl.add_self_loop(molecule)\n",
    "\n",
    "print(f'Num nodes: {molecule.num_nodes()}')\n",
    "print(f'Num edges: {molecule.num_edges()}')\n",
    "print(f'Num source nodes: {molecule.num_src_nodes()}')\n",
    "\n",
    "nx.draw_kamada_kawai(molecule.to_networkx(), with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(molecule.num_edges()):\n",
    "    source_edge = molecule_lg.edges()[0][i].item()\n",
    "    destination_edge = molecule_lg.edges()[1][i].item()\n",
    "\n",
    "    print(molecule.find_edges(source_edge))\n",
    "    print(molecule.find_edges(destination_edge))\n",
    "    print()\n",
    "\n",
    "for i in range(molecule.num_edges()):\n",
    "    print(molecule.find_edges(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.tensor([[molecule.find_edges(i)[1]] for i in range(molecule.num_edges())])\n",
    "\n",
    "for i in mask:\n",
    "    print(i.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(molecule_lg.edges())\n",
    "print(molecule_lg.adjacency_matrix().to_dense())\n",
    "\n",
    "nx.draw_circular(molecule_lg.to_networkx(), with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molecule.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molecule.ndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molecule.edata['feat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate edge attention\n",
    "W = torch.ones([3])\n",
    "edge_attention = molecule_lg.adjacency_matrix() @ molecule.edata['feat'].float() @ W\n",
    "edge_attention = nn.Softmax(dim=0)(edge_attention)\n",
    "\n",
    "edge_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate node attention\n",
    "W = torch.ones([9])\n",
    "node_attention = molecule.adjacency_matrix() @ molecule.ndata['feat'].float() @ W\n",
    "node_attention = nn.Softmax(dim=0)(node_attention)\n",
    "\n",
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency = molecule.adjacency_matrix().to_dense()\n",
    "\n",
    "adjacency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention adjacency matrix\n",
    "for edge in range(molecule.number_of_edges()):\n",
    "    i = molecule.edges()[0][edge].item()\n",
    "    j = molecule.edges()[1][edge].item()\n",
    "    attention = edge_attention[edge].item()\n",
    "\n",
    "    print(i, j, attention)\n",
    "    \n",
    "    adjacency[i][j] = attention\n",
    "\n",
    "adjacency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_lg = molecule_lg.adjacency_matrix().to_dense()\n",
    "\n",
    "print(adjacency_lg)\n",
    "\n",
    "nx.draw_kamada_kawai(molecule_lg.to_networkx(), with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention lg adjacency matrix\n",
    "\n",
    "for i in range(molecule.number_of_edges()):\n",
    "    for j in range(molecule.number_of_edges()):\n",
    "        if adjacency_lg[i][j] == 1:\n",
    "            assert molecule.edges()[1][i].item() == molecule.edges()[0][j].item()\n",
    "            \n",
    "            connecting_node = molecule.edges()[1][i].item()\n",
    "            attention = node_attention[connecting_node].item()\n",
    "\n",
    "            adjacency_lg[i][j] = attention\n",
    "\n",
    "# adjacency_lg @ molecule.edata['feat'].float()\n",
    "adjacency_lg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to use it (edge 0 here -> edge 0 in molecule destination node?)\n",
    "\n",
    "molecule_lg.edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connecting_node = molecule.edges()[1][molecule_lg.edges()[0][16].item()].item()\n",
    "\n",
    "connecting_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, in_feats):\n",
    "        super().__init__()\n",
    "        self.key_linear = nn.Linear(in_feats, 1)\n",
    "        self.value_linear = nn.Linear(in_feats, in_feats)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        key = self.key_linear(inputs)\n",
    "        value = self.value_linear(inputs)\n",
    "\n",
    "        x = value @ inputs.t() @ key\n",
    "        x = F.softmax(x, dim=0)\n",
    "\n",
    "        return x\n",
    "\n",
    "class AttentionGraphConv(nn.Module):\n",
    "    def __init__(self, in_feats):\n",
    "        self.linear = nn.Linear(in_feats, in_feats)\n",
    "\n",
    "    def forward(self, inputs: torch.Tensor(), adjacency: torch.Tensor(), attention: torch.Tensor()):\n",
    "        x = adjacency * attention @ inputs\n",
    "        x = self.linear(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Head(nn.Module):\n",
    "    def __init__(self, node_in_feats, edge_in_feats):\n",
    "        super().__init__()\n",
    "        self.node_attention = SelfAttention(node_in_feats)\n",
    "        self.node_query_linear = nn.Linear(node_in_feats, node_in_feats)\n",
    "        self.node_query_conv = AttentionGraphConv(node_in_feats)\n",
    "        self.edge_attention = SelfAttention(edge_in_feats)\n",
    "        self.edge_query_linear = nn.Linear(edge_in_feats, edge_in_feats)\n",
    "        self.edge_query_conv = AttentionGraphConv(edge_in_feats)\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        g: dgl.DGLGraph, \n",
    "        g_adjacency: torch.Tensor, \n",
    "        lg: dgl.DGLGraph, \n",
    "        lg_adjacency: torch.Tensor, \n",
    "        node_feats: torch.Tensor, \n",
    "        edge_feats: torch.Tensor,\n",
    "    ):\n",
    "        node_attention = self.node_attention(node_feats)\n",
    "        node_query = self.node_query_mlp(node_feats)\n",
    "\n",
    "        edge_attention = self.edge_attention(edge_feats)\n",
    "        edge_query = self.edge_query_mlp(edge_feats)\n",
    "\n",
    "        node_attention_to_edge = torch.tensor([[node_attention[g.find_edges(edge)[1]]] for edge in range(g.num_edges())])\n",
    "        \n",
    "        edge_query = self.edge_query_conv(edge_query, lg_adjacency, node_attention_to_edge)\n",
    "\n",
    "        \n",
    "\n",
    "        return node_attention, edge_attention\n",
    "\n",
    "node_feats = molecule.ndata['feat'].float()\n",
    "edge_feats = molecule.edata['feat'].float()\n",
    "\n",
    "attentions = Head(9, 3)(node_feats, edge_feats)\n",
    "\n",
    "print(attentions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molecule_lg.adjacency_matrix().shape[0]\n",
    "mask = torch.tensor([[molecule.find_edges(i)[1]] for i in range(molecule.num_edges())])\n",
    "\n",
    "node_attention = attentions[0]\n",
    "\n",
    "edge_attention_from_node = torch.tensor([[node_attention[molecule.find_edges(edge)[1]]] for edge in range(molecule.num_edges())])\n",
    "\n",
    "molecule_lg.adjacency_matrix().to_dense() * edge_attention_from_node @ molecule.edata['feat'].float()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}